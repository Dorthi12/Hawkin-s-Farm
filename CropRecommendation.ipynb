{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQfEPqvoF3VTcoWZo2tekF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dorthi12/Hawkin-s-Farm/blob/dorthi-ml/CropRecommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crop Recommendation"
      ],
      "metadata": {
        "id": "iD13JGBcv36d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl1_Gcb0v26d",
        "outputId": "7de94777-cb4f-4b7a-9acf-ab9ab969c8c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Products: (5000, 7)\n",
            "Transactions: (25000, 4)\n",
            "User–Item matrix shape: (800, 5000)\n",
            "Similarity matrix: (5000, 5000)\n",
            "Precision@10: 0.0037\n",
            "Model saved at /content/recommender_model.pkl\n"
          ]
        }
      ],
      "source": [
        "# ===============================\n",
        "# 1) LOAD DATA\n",
        "# ===============================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix, save_npz\n",
        "import joblib\n",
        "\n",
        "pricing = pd.read_csv(\"/content/pricing_synthetic_generated.csv\")\n",
        "tx = pd.read_csv(\"/content/transactions_synthetic_generated.csv\")\n",
        "\n",
        "print(\"Products:\", pricing.shape)\n",
        "print(\"Transactions:\", tx.shape)\n",
        "\n",
        "# ===============================\n",
        "# 2) BUILD USER → ITEM MATRIX\n",
        "# ===============================\n",
        "# Map SKU → index\n",
        "sku_list = pricing['sku'].tolist()\n",
        "sku_to_idx = {sku:i for i,sku in enumerate(sku_list)}\n",
        "idx_to_sku = {i:sku for sku,i in sku_to_idx.items()}\n",
        "\n",
        "num_users = tx[\"user_id\"].max() + 1\n",
        "num_items = len(sku_list)\n",
        "\n",
        "# Aggregate quantity per (user, sku)\n",
        "from collections import defaultdict\n",
        "agg = defaultdict(float)\n",
        "for _, row in tx.iterrows():\n",
        "    agg[(row.user_id, sku_to_idx[row.sku])] += row.quantity\n",
        "\n",
        "rows, cols, vals = [], [], []\n",
        "for (u,i), q in agg.items():\n",
        "    rows.append(u)\n",
        "    cols.append(i)\n",
        "    vals.append(q)\n",
        "\n",
        "user_item = csr_matrix((vals, (rows, cols)), shape=(num_users, num_items))\n",
        "\n",
        "print(\"User–Item matrix shape:\", user_item.shape)\n",
        "\n",
        "# ===============================\n",
        "# 3) HOLDOUT TEST SET (one item per user)\n",
        "# ===============================\n",
        "train = user_item.copy().tolil()\n",
        "test_pairs = []\n",
        "\n",
        "for u in range(num_users):\n",
        "    row = user_item.getrow(u).tocoo()\n",
        "    if row.nnz == 0:\n",
        "        continue\n",
        "    heldout = np.random.choice(row.col)\n",
        "    train[u, heldout] = 0\n",
        "    test_pairs.append((u, heldout))\n",
        "\n",
        "train = train.tocsr()\n",
        "\n",
        "# ===============================\n",
        "# 4) ITEM–ITEM SIMILARITY (COSINE)\n",
        "# ===============================\n",
        "item_user = train.T.tocsr()              # shape: items × users\n",
        "dense = item_user.toarray()\n",
        "norms = np.linalg.norm(dense, axis=1, keepdims=True)\n",
        "norms[norms == 0] = 1\n",
        "dense_norm = dense / norms\n",
        "\n",
        "similarity = dense_norm @ dense_norm.T   # cosine sim\n",
        "np.fill_diagonal(similarity, 0)\n",
        "\n",
        "print(\"Similarity matrix:\", similarity.shape)\n",
        "\n",
        "# ===============================\n",
        "# 5) RECOMMENDER FUNCTION\n",
        "# ===============================\n",
        "def recommend_for_user(user_id, K=10):\n",
        "    user_vector = train.getrow(user_id).toarray().ravel()\n",
        "    bought = np.where(user_vector > 0)[0]\n",
        "\n",
        "    if len(bought) == 0:\n",
        "        # Cold start → Popular items based on units_sold\n",
        "        popular = pricing.groupby(\"sku\")[\"units_sold\"].sum().sort_values(ascending=False)\n",
        "        return popular.head(K).index.tolist()\n",
        "\n",
        "    # score items by similarity to bought items\n",
        "    scores = similarity[bought].sum(axis=0)\n",
        "    scores[bought] = -np.inf  # do not recommend already-bought items\n",
        "\n",
        "    top_idx = np.argsort(-scores)[:K]\n",
        "    return [idx_to_sku[i] for i in top_idx]\n",
        "\n",
        "# ===============================\n",
        "# 6) EVALUATION — PRECISION@10\n",
        "# ===============================\n",
        "hits = 0\n",
        "total = 0\n",
        "\n",
        "for u, item_idx in test_pairs:\n",
        "    recs = recommend_for_user(u, K=10)\n",
        "    if idx_to_sku[item_idx] in recs:\n",
        "        hits += 1\n",
        "    total += 1\n",
        "\n",
        "precision_at10 = hits / total\n",
        "print(\"Precision@10:\", round(precision_at10, 4))\n",
        "\n",
        "# ===============================\n",
        "# 7) SAVE MODEL\n",
        "# ===============================\n",
        "joblib.dump({\n",
        "    \"similarity_matrix\": similarity,\n",
        "    \"sku_to_idx\": sku_to_idx,\n",
        "    \"idx_to_sku\": idx_to_sku,\n",
        "    \"train_matrix_path\": \"/content/train_user_item.npz\"\n",
        "}, \"/content/recommender_model.pkl\")\n",
        "\n",
        "print(\"Model saved at /content/recommender_model.pkl\")\n",
        "\n"
      ]
    }
  ]
}